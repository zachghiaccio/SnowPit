{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "74e721c4-5532-491c-a16b-cc317951ffe6",
   "metadata": {},
   "source": [
    "# SNODAS Data Access\n",
    "\n",
    "This script is designed to access and process data from the Snow Data Assimilation (SNODAS) system. \n",
    "\n",
    "Data is accessed through NSIDC. Because SNODAS is not available through the cloud, we must use HTTPS data querying to download and process the data.\n",
    "\n",
    "This script is adapted from code written by Aakash Ahamed (https://github.com/kashingtonDC/SNODAS)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a133a377-2eaf-4de6-97b0-3907195d233d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "import os\n",
    "import time\n",
    "import gzip\n",
    "import shutil\n",
    "\n",
    "import datetime\n",
    "import subprocess \n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd0e04c1-5749-40bb-9ccb-0f7bf801b949",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Year/month/day setup for SNODAS archive\n",
    "year = \"2023\"\n",
    "month = \"Mar\" # 3-character abbreviation for month\n",
    "day = \"03\" # 2-digit number for day of month\n",
    "\n",
    "# Get urls for SNODAS archive\n",
    "archive_url = f'https://noaadata.apps.nsidc.org/NOAA/G02158/masked/{year}/{day}_{month}/'\n",
    "r = requests.get(archive_url)\n",
    "data = BeautifulSoup(r.text, \"html.parser\")\n",
    "\n",
    "# Extract data from SNODAS archive\n",
    "dir = \"/home/jovyan/shared-public/SnowPit/tmp/\"\n",
    "for l in data.find_all(\"a\")[1:]:\n",
    "    r = requests.get(archive_url+l['href'])\n",
    "    with open(os.path.join(dir, l['href']), 'wb') as f:\n",
    "        f.write(r.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b65b45ae-664c-4c61-aac9-c525def854a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_tarfile(tarfile, writedir, snovars=['1034']):\n",
    "    # Extract date from tarfile\n",
    "    date = os.path.splitext(os.path.split(tarfile)[1])[0].replace(\"SNODAS_\",\"\")\n",
    "    \n",
    "    # Untar the files using OS commands\n",
    "    cmd = '''tar -xvf {} -C {}'''.format(tarfile, writedir)\n",
    "    os.system(cmd)\n",
    "\n",
    "    # Find untarred .gz files\n",
    "    gz_files = [os.path.join(writedir,x) for x in os.listdir(writedir) if date in x if x.endswith(\".gz\")]\n",
    "\n",
    "    # Get variable strings from each file\n",
    "    varstrs = [x[x.find(\"ssmv\")+5:x.find(\"ssmv\")+9] for x in gz_files]\n",
    "\n",
    "    # Compare variable strings to wanted variables\n",
    "    for varstr,file in zip(varstrs, gz_files):\n",
    "        outfn = os.path.splitext(file)[0]\n",
    "        if varstr in snovars:\n",
    "            with gzip.open(file, 'r') as f_in, open(outfn, 'wb') as f_out:\n",
    "                shutil.copyfileobj(f_in, f_out)\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "    datfiles = [os.path.join(writedir,x) for x in os.listdir(writedir) if date in x if x.endswith(\".dat\")]\n",
    "    txtfiles = [os.path.join(writedir,x) for x in os.listdir(writedir) if date in x if x.endswith(\".txt\")]\n",
    "    gz_files = [os.path.join(writedir,x) for x in os.listdir(writedir) if date in x if x.endswith(\".gz\")]\n",
    "\n",
    "    return datfiles, txtfiles, gz_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d425db93-03fb-48e9-9628-395f7cb110b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def txt2hdr(txtfiles, writedir):\n",
    "    dates = [x[x.find(\"TS\")+2:x.find(\"TS\")+10] for x in txtfiles]\n",
    "    ymd = [datetime.datetime.strptime(x, '%Y%m%d') for x in dates]\n",
    "    hdrfiles = []\n",
    "    \n",
    "    # Account for datum change in 2013\n",
    "    for date,file in zip(ymd, txtfiles):\n",
    "        if date < datetime.datetime(2013, 10, 1):\n",
    "            hdrfile = os.path.join(writedir,\"../pre_10_2013.hdr\")\n",
    "        if date >= datetime.datetime(2013, 10, 1):\n",
    "            hdrfile = os.path.join(writedir,\"../post_10_2013.hdr\")\n",
    "        \n",
    "        # Spec dest file\n",
    "        snofn = os.path.split((os.path.splitext(file)[0]))[1] + \".hdr\"\n",
    "        snowpath = os.path.join(writedir,snofn)\n",
    "        hdrfiles.append(snowpath)\n",
    "        shutil.copy(hdrfile,snowpath)\n",
    "\n",
    "    return hdrfiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ac3a3de-37db-4c92-a9f5-148e17265414",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dat2tif(datfiles, writedir):\n",
    "    prod_lookup = dict({\n",
    "        \"1034\": \"SNWE\"\n",
    "    })\n",
    "\n",
    "    outfnsv1 = {}\n",
    "\n",
    "    for file in datfiles:\n",
    "        date = file[file.find(\"TS\")+2:file.find(\"TS\")+10]\n",
    "        for k,v in prod_lookup.items():\n",
    "            if k in file:\n",
    "                outfnsv1[file] = date + v + \".tif\"\n",
    "\n",
    "    outfnsvf = {}\n",
    "    for k,v in outfnsv1.items():\n",
    "        outfnsvf[k] = os.path.join(writedir, v)\n",
    "\n",
    "    outfiles = []\n",
    "    for infile,outfile in outfnsvf.items():\n",
    "        if not os.path.exists(outfile):\n",
    "            cmd = '''gdal_translate -of GTIff -a_srs '+proj=longlat +ellps=WGS84 +no_defs' -a_nodata -9999 -a_ullr -124.73333333 52.87500000 -66.94166667 24.95000000 {} {}'''.format(infile,outfile)\n",
    "            os.system(cmd)\n",
    "        else:\n",
    "            print(\"{} already exists - moving to next file\".format(outfile))\n",
    "\n",
    "        outfiles.append(outfile)\n",
    "\n",
    "    return outfiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21c49aab-70a0-474e-87fe-effbc3cdc804",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tmp_dir = \"/home/jovyan/shared-public/SnowPit/tmp/\"\n",
    "tarfiles = os.listdir(tmp_dir)\n",
    "\n",
    "for tar in tarfiles:\n",
    "    file = os.path.join(tmp_dir, tar)\n",
    "    dat, txt, gz = process_tarfile(file, \"/home/jovyan/shared-public/SnowPit/tmp/\")\n",
    "\n",
    "    hdrfiles = txt2hdr(txt, tmp_dir)\n",
    "    tiffiles = dat2tif(dat, tmp_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10e7bdf0-f1bb-4d00-94f1-a39a463c9568",
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = 6935\n",
    "lines = 3351\n",
    "bands = 1\n",
    "header_offset = 0\n",
    "file_type = \"ENVI Standard\"\n",
    "data_type = 2\n",
    "interleave = \"bsq\"\n",
    "byte_order = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f735a21b-5022-42b9-a29b-2f4273e8a62e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_envi_header(txt_path, hdr_path, samples, lines, bands, data_type, interleave, byte_order):\n",
    "    \"\"\"\n",
    "    Creates an ENVI header (.hdr) file.\n",
    "\n",
    "    Args:\n",
    "        txt_path (str): Path to the input .txt file (used only for the 'map info' field).\n",
    "        hdr_path (str): Path to save the output .hdr file.\n",
    "        description (str): Description of the data.\n",
    "        samples (int): Number of samples (columns).\n",
    "        lines (int): Number of lines (rows).\n",
    "        bands (int): Number of bands.\n",
    "        data_type (int): ENVI data type code (e.g., 1 for byte, 4 for float).\n",
    "        interleave (str): Interleave type ('bsq', 'bip', or 'bil').\n",
    "        byte_order (int): Byte order (0 for little-endian, 1 for big-endian).\n",
    "    \"\"\"\n",
    "    with open(txt_path, 'r') as file:\n",
    "      lines_txt = file.readlines()\n",
    "    map_info_line = next((line for line in lines_txt if \"map info\" in line.lower()), None)\n",
    "\n",
    "    with open(hdr_path, 'w') as hdr_file:\n",
    "        hdr_file.write(\"ENVI\\n\")\n",
    "        hdr_file.write(f\"description = {{{description}}}\\n\")\n",
    "        hdr_file.write(f\"samples = {samples}\\n\")\n",
    "        hdr_file.write(f\"lines = {lines}\\n\")\n",
    "        hdr_file.write(f\"bands = {bands}\\n\")\n",
    "        hdr_file.write(f\"header offset = 0\\n\")\n",
    "        hdr_file.write(f\"file type = ENVI Standard\\n\")\n",
    "        hdr_file.write(f\"data type = {data_type}\\n\")\n",
    "        hdr_file.write(f\"interleave = {interleave}\\n\")\n",
    "        hdr_file.write(f\"sensor type = Unknown\\n\")\n",
    "        hdr_file.write(f\"byte order = {byte_order}\\n\")\n",
    "        if map_info_line:\n",
    "          hdr_file.write(f\"{map_info_line}\")\n",
    "        else:\n",
    "          hdr_file.write(f\"map info = {{UTM, 1.000, 1.000, 0.000, 0.000, 1, 1, WGS-84, units=Meters}}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59829467-af57-4dfc-afe3-ebe3128912de",
   "metadata": {},
   "outputs": [],
   "source": [
    "## TODO: Test the above function for developing the headers"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
