{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f2f2717e-bd95-4152-88f6-9d81e9b2dfe0",
   "metadata": {},
   "source": [
    "# Snow Pit Data Access and SWE Calculation\n",
    "\n",
    "This notebook is designed to access data from snow pits gathered during the SnowEx field campaigns. There are two embedded examples: a simple use case with `earthaccess` and snow depth data, and a more advanced example using the SnowEx database (`snowexsql`) to obtain snow depth and density.\n",
    "\n",
    "The `snowexsql` example uses code from a SnowEx Database example found here: https://snowexsql.readthedocs.io/en/latest/gallery/plot_pit_swe_example.html. Additional thanks goes to Anthony Arendt and Joachim Meyer for their insights on proper syntax with the code.\n",
    "\n",
    "This notebook uses the `contextily` and `cmcrameri` packages for map plotting and colorblind-friendly coloring, respectively. Use the below cell to install both, and to ensure that `snowexsql` is up-to-date."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b0455a5-9b6c-460b-bb16-463e3be3890b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install contextily cmcrameri\n",
    "!pip install snowexsql -U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1adec356-f881-4906-a3cd-ad84ccc47d1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import earthaccess\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import os\n",
    "import tempfile\n",
    "from shapely.geometry import Point\n",
    "import shutil\n",
    "import cmcrameri.cm as cmc\n",
    "import matplotlib.pyplot as plt\n",
    "import contextily as ctx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39f03762-6019-4378-a574-9ecdf26076e3",
   "metadata": {},
   "source": [
    "## earthaccess example\n",
    "For the earthaccess example, we are using the DOI of the \"SnowEx20 Community Snow Depth Probe Measurements, Version 1\" obtained at Grand Mesa, CO. These files are stored in CSV format, and contain snow depths using magnaprobes, Mesa2 tablets, and pit rulers.\n",
    "\n",
    "Note that the `short_name` of the dataset is provided in the cell. This may be used as an alternative to the DOI, if desired."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ce46209-b63d-4586-800c-19299b2e9118",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Authenticate with Earthdata Login servers\n",
    "auth = earthaccess.login(strategy=\"interactive\")\n",
    "\n",
    "# Search for granules\n",
    "results = earthaccess.search_data(\n",
    "    #short_name=\"SNEX20_SD\",\n",
    "    doi = \"10.5067/9IA978JIACAR\",\n",
    "    temporal=('2020-01-01', '2020-03-01'),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3921406e-d469-474b-a22b-050ba811b7ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(results[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed536246-71ae-4353-b5e8-b8bb3026b04c",
   "metadata": {},
   "source": [
    "Our query returned a single CSV file over the time frame of interest. Note how we did not include a spatial bound for the data here - this is because the dataset of interest only gathered data over Grand Mesa, CO.\n",
    "\n",
    "To obtain the data, we will create a temporary directory (`tempfile.mkdtemp()`), and load the data into a GeoDataFrame. The temporary directory (and data within) will be deleted after processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f120bf32-6f2f-4e9d-9447-f500ccb74dfc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create a temporary directory for downloads\n",
    "temp_dir = tempfile.mkdtemp()\n",
    "print(f\"Using temporary directory: {temp_dir}\")\n",
    "\n",
    "# Download the data to the temp directory\n",
    "downloaded_files = earthaccess.download(\n",
    "    results,\n",
    "    local_path=temp_dir,\n",
    ")\n",
    "print(f\"Downloaded {len(downloaded_files)} files to {temp_dir}\")\n",
    "\n",
    "# Process CSV files and convert to GeoDataFrame\n",
    "gdf = gpd.GeoDataFrame()\n",
    "csv_files = [file for file in downloaded_files if file.endswith('.csv')]\n",
    "if csv_files:\n",
    "    for i, csv_file in enumerate(csv_files):\n",
    "        print(f\"Processing: {os.path.basename(csv_file)}\")\n",
    "\n",
    "        # Read the csv file\n",
    "        tmp_df = pd.read_csv(csv_file)\n",
    "\n",
    "        # Convert to GeoDataFrame\n",
    "        geometry = [Point(xy) for xy in zip(tmp_df['Easting'], tmp_df['Northing'])]\n",
    "        tmp_gdf = gpd.GeoDataFrame(tmp_df, geometry=geometry, crs=\"EPSG:32612\")\n",
    "\n",
    "        # Add to final GeoDataFrame\n",
    "        gdf = pd.concat([gdf, tmp_gdf])\n",
    "\n",
    "print(\"All files processed.\")\n",
    "print(' ')\n",
    "print(f\"Removing temporary directory: {temp_dir}\")\n",
    "shutil.rmtree(temp_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dab5f3af-9487-4863-af7e-28fa1746d9ce",
   "metadata": {},
   "source": [
    "Fast and easy! We can now check out the contents of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b5d062e-9128-42ef-9da2-45110472f5c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a13417fd-8a62-4044-827d-6030dab0d75d",
   "metadata": {},
   "source": [
    "Some columns of interest include:\n",
    "* `Measurement Tool [...]`: The measurement tool used to measure snow depth: MP = magnaprobe, M2 = Mesa2 tablet, and PR = pit ruler.\n",
    "* `Date [...]`: The date of the measurement, in yyyymmdd format.\n",
    "* `PitID`: The designated pit ID associated with the measurement.\n",
    "* `Depth (cm)`: Snow depth, in centimeters.\n",
    "* `elevation (m)`: Surface elevation at the location of the measurement.\n",
    "\n",
    "The key variables for this example - the measurement approach and the depth - could use renaming. Let's do that now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6838c053-5ca0-4cff-8c35-63e3914b3909",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf.rename(columns={\"Measurement Tool (MP = Magnaprobe; M2 = Mesa 2; PR = Pit Ruler)\": 'measurement_tool',\n",
    "                    \"Depth (cm)\": 'snow_depth'}, inplace=True\n",
    "          )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4e6050c-e7ff-46db-a263-26ed4b71adf6",
   "metadata": {},
   "source": [
    "Now, let's make a map plot showing the locations of the measurements, colored by snow depth value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2126dd5-54b1-4b2d-9ae1-45bbd7d2656f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "\n",
    "# Define min/max values for colormap\n",
    "vmin = gdf['snow_depth'].quantile(0.15)\n",
    "vmax = gdf['snow_depth'].quantile(0.85)\n",
    "\n",
    "# Convert to EPSG:3857 to match with the contextily basemap\n",
    "if gdf.crs != 'EPSG:3857':\n",
    "    gdf_web = gdf.to_crs(epsg=3857)\n",
    "    ax.set_xlim(gdf_web.total_bounds[[0, 2]])\n",
    "    ax.set_ylim(gdf_web.total_bounds[[1, 3]])\n",
    "else:\n",
    "    ax.set_xlim(gdf.total_bounds[[0, 2]])\n",
    "    ax.set_ylim(gdf.total_bounds[[1, 3]])\n",
    "\n",
    "# Plot snow depths by location\n",
    "gdf_web.plot(\n",
    "    column='snow_depth',\n",
    "    ax=ax,\n",
    "    markersize=10,\n",
    "    cmap='cmc.navia',\n",
    "    legend=True,\n",
    "    legend_kwds={'shrink': 0.3, 'label': 'Snow depth [cm]'},\n",
    "    vmin=vmin,\n",
    "    vmax=vmax\n",
    ")\n",
    "\n",
    "# Add topographic map for spatial reference\n",
    "ctx.add_basemap(\n",
    "    ax, \n",
    "    source=ctx.providers.OpenTopoMap,\n",
    "    zoom='auto'\n",
    ")\n",
    "\n",
    "ax.set_xlabel(\"Easting [m]\", fontsize=14)\n",
    "ax.set_ylabel(\"Northing [m]\", fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eed8333e-7ad3-483c-abf5-13a472e87c31",
   "metadata": {},
   "source": [
    "The above map looks pretty cool, but we might be interested to see how the different measurement approaches differ in accuracy and uncertainty. Let's now use `seaborn` to generate snow depth histograms for each instrument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70a5eeb8-099c-49b3-8815-01023dbbc554",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "# Get the unique measurement values\n",
    "unique_measurements = gdf['measurement_tool'].unique()\n",
    "\n",
    "# Make 1x3 figure for each tool\n",
    "fig, axs = plt.subplots(1, 3, figsize=(18, 6), sharey=True)\n",
    "# Set consistent background\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "# Loop through unique measurement tools to make a plot for each\n",
    "for i, measurement in enumerate(unique_measurements):\n",
    "    subset = gdf[gdf['measurement_tool']==measurement]\n",
    "\n",
    "    # Make a KDE plot normalized by density, rather than raw counts\n",
    "    sns.histplot(subset['snow_depth'],\n",
    "                 ax=axs[i],\n",
    "                 kde=True,\n",
    "                 bins=30,\n",
    "                 edgecolor='black',\n",
    "                 linewidth=0.5,\n",
    "                 stat=\"density\",\n",
    "                 common_norm=False\n",
    "                )\n",
    "\n",
    "    # Draw a vertical line at the median snow depth\n",
    "    median_val = subset['snow_depth'].median()\n",
    "    axs[i].axvline(median_val, color='green', linestyle='--', linewidth=2,\n",
    "                   label=f'Median: {median_val} cm')\n",
    "\n",
    "    # Add text that notes the total number of measurements\n",
    "    axs[i].text(\n",
    "            0.05, 0.95,\n",
    "            f\"n = {len(subset)}\",\n",
    "            transform=axs[i].transAxes,\n",
    "            fontsize=12,\n",
    "            verticalalignment='top'\n",
    "    )\n",
    "\n",
    "    axs[i].set_title(f'{measurement}', fontsize=14)\n",
    "    axs[i].set_xlabel(\"Depth (cm)\", fontsize=14)\n",
    "\n",
    "    # Set y-label only for first figure\n",
    "    if i == 0:\n",
    "        axs[i].set_ylabel(\"Density\", fontsize=14)\n",
    "    else:\n",
    "        axs[i].set_ylabel(\" \")\n",
    "\n",
    "    axs[i].legend(loc='upper right')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7c53f3f-6aec-4334-ae53-e95101df039d",
   "metadata": {},
   "source": [
    "Thanks to this plot, we can make a comparison between the different instruments. The magnaprobe depths are the lowest by a slight margin, and also appear to have the lowest spread in depths. The Mesa2 tablet depths are the highest by a few centimeters, and the pit rulers have the highest spread."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8898f952-d2b5-4c19-a000-6051bc45186d",
   "metadata": {},
   "source": [
    "## SnowEx Database Example\n",
    "We will now attempt to achieve the same result, but with the SnowEx Database. Before we dive in, we will see what measurements are available through the `snowexsql` package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f5ef930-69d6-459b-b989-875759619cb2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from snowexsql.api import PointMeasurements, LayerMeasurements\n",
    "\n",
    "# Instantiate the class to use the properties!\n",
    "measurements = PointMeasurements()\n",
    "\n",
    "# Get the unique data names/types in the table\n",
    "results = measurements.all_types\n",
    "print('Available types = {}'.format(', '.join([str(r) for r in results])))\n",
    "\n",
    "# Get the unique instrument in the table\n",
    "results = measurements.all_instruments\n",
    "print('\\nAvailable Instruments = {}'.format(', '.join([str(r) for r in results])))\n",
    "\n",
    "# Get the unique dates in the table\n",
    "results = measurements.all_dates\n",
    "print('\\nAvailable Dates = {}'.format(', '.join(sorted([str(r) for r in results]))))\n",
    "\n",
    "# Get the unique site names in the table\n",
    "results = measurements.all_site_names\n",
    "print('\\nAvailable sites = {}'.format(', '.join([str(r) for r in results])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8d23db4-355c-4658-a695-7302eac90dbf",
   "metadata": {},
   "source": [
    "So, we have quite of data available! The date range spans from September 2019 to March 2023, and we have snow depth, SWE, and density measurements accessible for multiple sites and instrument types.\n",
    "\n",
    "Since this is a generally faster method to access data, we will take an extra step and calculate SWE from the available snow depth and density data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d9f93c6-2e9c-4139-8520-090b9db88f7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime \n",
    "\n",
    "# Find some snow depth measurements at the Grand Mesa in early 2020.\n",
    "magnaprobe = measurements.from_filter(\n",
    "    type=\"depth\",\n",
    "    site_name=\"Grand Mesa\",\n",
    "    instrument=\"magnaprobe\",\n",
    "    date_less_equal=datetime(2020, 3, 1),\n",
    "    date_greater_equal=datetime(2020, 1, 1),\n",
    "    limit=38000\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96d2a5dc-1ee3-413f-bebd-9985f056279c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "magnaprobe.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85b643b3-3282-4e97-ae22-06a506facb85",
   "metadata": {},
   "source": [
    "A breakdown of the query:\n",
    "* `type`: The type of measurement we want (depth, swe, density, etc.)\n",
    "* `instrument`: The instrument used to obtain the measurement. Here, we obtained `magnaprobe` measurements only, but below we will also specify the `mesa2` and `pit ruler` measurements.\n",
    "* `date_less_equal`: The latest date for any observations. Here, our end date is March 1, 2020.\n",
    "* `date_greater_equal`: The start date for our observations. Here, it is January 1, 2020.\n",
    "* `limit`: The maximum number of observations for our query. Larger numbers will result in longer loading times, though `38000` works fairly quickly.\n",
    "\n",
    "The below plotting cell is identical to the one used in the `earthaccess` example. Let's see if they agree!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ea33ebe-0344-4b03-9c21-57ca0d8bfdd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "\n",
    "# Define min/max values for colormap\n",
    "vmin = magnaprobe['value'].quantile(0.15)\n",
    "vmax = magnaprobe['value'].quantile(0.85)\n",
    "\n",
    "# Convert to EPSG:3857 to match with the contextily basemap\n",
    "if magnaprobe.crs != 'EPSG:3857':\n",
    "    gdf_web = magnaprobe.to_crs(epsg=3857)\n",
    "    ax.set_xlim(gdf_web.total_bounds[[0, 2]])\n",
    "    ax.set_ylim(gdf_web.total_bounds[[1, 3]])\n",
    "else:\n",
    "    gdf_web = magnaprobe\n",
    "    ax.set_xlim(gdf.total_bounds[[0, 2]])\n",
    "    ax.set_ylim(gdf.total_bounds[[1, 3]])\n",
    "\n",
    "# Plot snow depths by location\n",
    "gdf_web.plot(\n",
    "    column='value',\n",
    "    ax=ax,\n",
    "    markersize=10,\n",
    "    cmap='cmc.navia',\n",
    "    legend=True,\n",
    "    legend_kwds={'shrink': 0.5, 'label': 'Snow depth [cm]'},\n",
    "    vmin=vmin,\n",
    "    vmax=vmax\n",
    ")\n",
    "\n",
    "# Add topographic map for spatial reference\n",
    "ctx.add_basemap(\n",
    "    ax, \n",
    "    source=ctx.providers.OpenTopoMap,\n",
    "    zoom='auto'\n",
    ")\n",
    "\n",
    "ax.set_xlabel(\"Easting [m]\", fontsize=14)\n",
    "ax.set_ylabel(\"Northing [m]\", fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f3e205c-0dcb-4619-91ad-18e72cff64af",
   "metadata": {},
   "source": [
    "It's quite close! We're missing out on a few locations, but the number of missing points is negligible.\n",
    "\n",
    "Now, we are going to calculate SWE. This means we need to grab snow density over the same domain. Note that in the below cell that no `instrument` is defined. This is because a bulk density is provided over a handful of snow pits, with no specific instrument defined in the SnowEx Database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79109c72-1725-4819-b3cf-ac9970f87367",
   "metadata": {},
   "outputs": [],
   "source": [
    "density = measurements.from_filter(\n",
    "    type=\"density\",\n",
    "    site_name=\"Grand Mesa\",\n",
    "    date_less_equal=datetime(2020, 3, 1),\n",
    "    date_greater_equal=datetime(2020, 1, 1),\n",
    "    limit=38000\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "611fbd9d-1cb3-42ae-9c48-90463c3e9477",
   "metadata": {},
   "outputs": [],
   "source": [
    "density.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe17db57-6949-4765-8683-77fd6824322a",
   "metadata": {},
   "source": [
    "We have a much smaller number of snow density measurements than we do snow depths. To keep things simple, we are going to find the median density value across the domain, then use that value to calculate SWE for every snow depth measurement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ed7db31-70c5-4c7a-a3ac-b6bba3d6365f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate median density of available data\n",
    "density_median = density['value'][density['value']>=0].median()\n",
    "\n",
    "# Make a rough SWE calculation with median density and available snow depths\n",
    "magnaprobe['swe'] = magnaprobe['value'] * (density_median*10e-6*1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "814ac765-e56a-4347-b9ff-98685363906e",
   "metadata": {},
   "source": [
    "We are going to again repeat the process with the Mesa2 tablets and the pit rulers. As with `earthaccess`, we will use separate queries to grab these snow depths, then convert them to SWE with the median snow density. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f78d2e62-1498-478b-accf-bef96c2ee97d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Make a query for the Mesa2 tablets\n",
    "mesa2 = measurements.from_filter(\n",
    "    type=\"depth\",\n",
    "    site_name=\"Grand Mesa\",\n",
    "    instrument=\"mesa\",\n",
    "    date_less_equal=datetime(2020, 3, 1),\n",
    "    date_greater_equal=datetime(2020, 1, 1),\n",
    "    limit=38000\n",
    ")\n",
    "\n",
    "print(f\"Found {len(mesa2)} Mesa2 tablet measurements.\")\n",
    "\n",
    "# Do the same for pit ruler measurements\n",
    "pit_ruler = measurements.from_filter(\n",
    "    type=\"depth\",\n",
    "    site_name=\"Grand Mesa\",\n",
    "    instrument=\"pit ruler\",\n",
    "    date_less_equal=datetime(2020, 3, 1),\n",
    "    date_greater_equal=datetime(2020, 1, 1),\n",
    "    limit=38000\n",
    ")\n",
    "\n",
    "print(f\"Found {len(pit_ruler)} pit ruler measurements.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aac5d92-b5aa-47b9-a7c9-50f07fb367cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate SWE for Mesa2 and pit ruler measurements\n",
    "mesa2['swe'] = mesa2['value'] * (density_median*10e-6*1000)\n",
    "pit_ruler['swe'] = pit_ruler['value'] * (density_median*10e-6*1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7abb3f5-29dc-4adc-b77d-8e9f2de6a6cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf = pd.concat([magnaprobe, mesa2, pit_ruler])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c28a4bca-40e2-4bde-bf62-eb16a82bbb2e",
   "metadata": {},
   "source": [
    "Finally, we will recreate the histogram figure from the `earthaccess` example, this time with SWE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2b0252e-1c47-4c1e-a26b-9261f7746bea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "# Get the unique measurement values\n",
    "unique_measurements = gdf['instrument'].unique()\n",
    "\n",
    "# Make 1x3 figure for each tool\n",
    "fig, axs = plt.subplots(1, 3, figsize=(18, 6), sharey=True)\n",
    "# Set consistent background\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "# Loop through unique measurement tools to make a plot for each\n",
    "for i, measurement in enumerate(unique_measurements):\n",
    "    subset = gdf[gdf['instrument']==measurement]\n",
    "\n",
    "    # Make a KDE plot normalized by density, rather than raw counts\n",
    "    sns.histplot(subset['swe'],\n",
    "                 ax=axs[i],\n",
    "                 kde=True,\n",
    "                 bins=30,\n",
    "                 edgecolor='black',\n",
    "                 linewidth=0.5,\n",
    "                 stat=\"density\",\n",
    "                 common_norm=False\n",
    "                )\n",
    "\n",
    "    # Draw a vertical line at the median snow depth\n",
    "    median_val = subset['swe'].median()\n",
    "    axs[i].axvline(median_val, color='green', linestyle='--', linewidth=2,\n",
    "                   label=f'Median: {median_val:.3g} mm')\n",
    "\n",
    "    # Add text that notes the total number of measurements\n",
    "    axs[i].text(\n",
    "            0.05, 0.95,\n",
    "            f\"n = {len(subset)}\",\n",
    "            transform=axs[i].transAxes,\n",
    "            fontsize=12,\n",
    "            verticalalignment='top'\n",
    "    )\n",
    "\n",
    "    axs[i].set_title(f'{measurement}', fontsize=14)\n",
    "    axs[i].set_xlabel(\"SWE (mm)\", fontsize=14)\n",
    "\n",
    "    # Set y-label only for first figure\n",
    "    if i == 0:\n",
    "        axs[i].set_ylabel(\"Density\", fontsize=14)\n",
    "    else:\n",
    "        axs[i].set_ylabel(\" \")\n",
    "\n",
    "    axs[i].legend(loc='upper right')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "113fa04b-b414-4c83-9549-5969bcd5f06f",
   "metadata": {},
   "source": [
    "Looks great! We have a distribution of SWE values for all three instruments, and they have reasonable values distributed similarly to the `earthaccess` depths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aa49b2a-0ea3-4d60-9b8c-647e2c7cc883",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
